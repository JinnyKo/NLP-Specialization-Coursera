# NLP-Specialization-by-Coursera
Specialization를 통해 공부한 내용과, 실습 및 과제를 하며 이슈가 있었던 부분들을 주석 및 자료를 첨부하여 정리해 놓았습니다. 

## Probabilistic Models
  - **Week 1**:
    Autocorrect, minimum edit distance, and dynamic programming, then build your own spellchecker to correct misspelled words.
  
  - **Week 2**:
    Markov chains and Hidden Markov models, then use them to create part-of-speech tags for a Wall Street Journal text corpus.
  
 - **Week 3**:
   How N-gram language models work by calculating sequence probabilities, then build your own autocomplete language model using a text corpus from Twitter.
  
 - **Week 4 (Important!!!) **:
   How word embeddings carry the semantic meaning of words, which makes them much more powerful for NLP tasks, then build your own Continuous bag-of-words model to create word embeddings from Shakespeare text.


