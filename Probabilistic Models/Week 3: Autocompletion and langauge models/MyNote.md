# N-gram vs HMM 
전 주에서 공부한 HMM과 직접적인 비교를 통해 N-gram의 개념에 대한 이해를 해보고자 한다. 
일단, HMM의 최종적인 목표는(지난 주 과제를 기준으로) 

1. **특정 품사를 가진 단어 예측**:주어진 문장에서 각 단어에 가장 적합한 품사를 예측. 이 경우, 모델은 각 단어의 은닉 상태(품사)와 그 단어(관측된 상태) 사이의 관계를 학습하여, **다음에 올 단어의 품사를 예측** 한다. => 문장 내에서 단어의 순서와 품사 간의 확률적 관계를 이용하는 것이다.

2. **단어가 특정 품사를 갖는 것을 예측**: 이는 HMM을 통해 주어진 단어가 특정 품사를 가질 확률을 예측. HMM은 각 상태(품사) 전이의 확률과 각 상태에서 특정 단어(관측)가 나타날 확률을 모델링하는데, 이 정보를 통해 **문장 내의 각 단어에 대해 가장 가능성이 높은 품사를 태깅**할 수 있다.

> #### **HMM을 사용한 품사 태깅의 주 목적은 특정 단어 뒤에 어떤 단어가 올지 직접 예측하는 것이 아니다!**.
> 대신, HMM은 주어진 단어 시퀀스에서 각 단어의 품사를 예측하는 데 초점을 맞춘다. 즉, 문장 내 각 단어의 품사를 결정하는 것이 주된 목표인것.

#### 따라서, "특정 단어 뒤에 어떤 단어가 올지"를 예측하려면 다른 종류의 언어 모델(예: N-gram, 신경망 기반 모델 등)을 사용하는 것.

# N-gram
: N-gram은 주어진 시퀀스에서 **N개의 연속적인 항목**(보통은 단어)을 분석하는 모델. N-gram 모델에서는 (N-1)개의 단어가 주어졌을 때 N번째 단어의 등장 확률을 계산한다. 

> **N개의 연속적인 항목이란**, 텍스트 내에서 연속적으로 나타나는 N개의 단어(또는 문자)를 의미한다. 이 개념은 단순히 전체 문서에서 임의로 선택된 N개의 단어가 아니라, 실제로 텍스트 내에서 인접해 있는 N개의 단어 시퀀스를 가리킨다.

> 예를 들어, "The quick brown fox jumps over the lazy dog"이라는 문장이 있다고 할 때:
- 2-gram(바이그램)의 경우, 연속적인 항목의 예는 "the quick", "quick brown", "brown fox", "fox jumps". 각각은 문장 내에서 바로 옆에 있는 단어들로 구성된다. 
- 3-gram(트라이그램)에서는 "the quick brown", "quick brown fox", "brown fox jumps" 이런식으로..
  
> N-gram 모델에서는 이러한 N개의 연속적인 단어를 기반으로 하여 N+1번째 단어의 등장 확률을 예측하는것. 예를 들어, 바이그램 모델에서 "quick brown" 다음에 어떤 단어가 올 확률을 계산한다면, 이전에 나타난 "quick brown"이라는 바이그램에 기반하여 다음에 올 수 있는 단어의 확률 분포를 추정하는 것이다. 

#### 따라서 N-gram 모델에서 **N은 고려하는 문맥의 크기**를 나타내며, 이 문맥을 바탕으로 다음 단어를 예측. => **단어의 순서와 문맥이 모델에 반영**되어 더 정확한 언어 모델링이 가능해진다. 


